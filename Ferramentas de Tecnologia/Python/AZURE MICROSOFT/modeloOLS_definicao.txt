O modelo OLS (Ordinary Least Squares) Ã© uma tÃ©cnica amplamente 
utilizada para ajustar uma linha reta aos dados, em um processo de regressÃ£o linear

O MÃ©todo dos MÃ­nimos Quadrados (MMQ), ou MÃ­nimos Quadrados OrdinÃ¡rios (MQO) 
ou OLS (do inglÃªs Ordinary Least Squares) Ã© uma tÃ©cnica de otimizaÃ§Ã£o 
matemÃ¡tica que procura encontrar o melhor ajuste para um conjunto de 
dados tentando minimizar a soma dos quadrados das diferenÃ§as entre o 
valor estimado e os dados observados

Como o OLS Ã© um mÃ©todo de regressÃ£o linear, um das principais 
suposiÃ§Ãµes Ã© que o modelo deve ser linear. Um grÃ¡fico de dispersÃ£o ou 
matriz do grÃ¡fico de dispersÃ£o pode ser utilizado para avaliar a 
linearidade entre a variÃ¡vel dependente e as variÃ¡veis explanatÃ³rias.

 O objetivo do modelo Ã© encontrar os melhores parÃ¢metros que minimizem a soma dos quadrados dos resÃ­duos (diferenÃ§as entre os valores reais e os valores previstos).

O modelo de regressÃ£o linear simples tem a forma:

Y Ã© igual a Beta_zero mais beta_um + erro( residuo - A diferenÃ§a real entre o Y e o valor predito)

Y Ã© a variÃ¡vel dependente (o que vocÃª quer prever ou explicar).
X Ã© a variÃ¡vel independente (a variÃ¡vel que vocÃª usa para prever).
Beta_zero Ã© o intercepto (chamado tambÃ©m de deslocamento ou termo 
constante). 
beta_um Ã© o coeficiente angular ( chamado de inclinaÃ§Ã£o ou pendente).
erro Ã© a diferenÃ§a entre o valor real de y e o valor predito

A razÃ£o de ter dois parÃ¢metros (inclinaÃ§Ã£o e deslocamento) Ã© porque, para ajustar uma linha reta aos dados, vocÃª precisa de dois elementos bÃ¡sicos para definir essa reta:

InclinaÃ§Ã£o: Define o "grau de sensibilidade" de 
ğ‘Œ
Y em relaÃ§Ã£o a 
ğ‘‹
X, ou seja, como 
ğ‘Œ
Y varia Ã  medida que 
ğ‘‹
X muda.
Deslocamento: Define onde a reta comeÃ§a (quando 
ğ‘‹
=
0
X=0) e garante que a reta passe pelo ponto adequado no grÃ¡fico.
Sem esses dois parÃ¢metros, a reta seria indefinida, ou seja, nÃ£o saberÃ­amos como a variÃ¡vel 
ğ‘Œ
Y depende de 
ğ‘‹
X e em que ponto a reta comeÃ§aria no grÃ¡fico.

Esses dois parÃ¢metros tornam o modelo OLS flexÃ­vel o suficiente para ajustar uma ampla variedade de relaÃ§Ãµes lineares entre as variÃ¡veis. O processo de mÃ­nimos quadrados Ã© justamente uma forma de encontrar os melhores valores de beta_um e Beta_zero que minimizam a soma dos erros quadrados.